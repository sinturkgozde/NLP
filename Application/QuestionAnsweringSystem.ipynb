{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['=', 'solo_singer\\\\n|birth_date', '=', '{', '{', 'birth', 'date|df=yes|1943|1|2', '}', '}', '\\\\n|birth_place', '=', '[', '[', '\\\\u00dcsk\\\\u00fcdar', ']'], ['of', 'the', 'war', '.', 'at', 'birth', ',', 'he', 'was', 'additionally', 'named', 'tosun', 'yusuf', 'after', 'his']]\n",
      "boşluk\n",
      "[['jones\\\\n|', 'birth_date', '=', '{', '{', 'birth', 'date|1947|1|8|df=y', '}', '}', '\\\\n|', 'birth_place', '=', '[', '[', 'brixton']]\n",
      "boşluk\n",
      "[['anderson\\\\n|', 'birth_date', '=', '{', '{', 'birth', 'date', 'and', 'age|1969|5|1', '}', '}', '\\\\n|', 'birth_place', '=', '[']]\n",
      "boşluk\n",
      "[['jackson\\\\n|', 'birth_date', '=', '{', '{', 'birth', 'date', 'and', 'age|1961|10|31|df=y', '}', '}', '\\\\n|', 'birth_place', '=', '['], ['31', ',', 'joan', 'jackson', 'gave', 'birth', 'to', 'her', 'first', 'child', 'at', 'wellington', 'hospital.\\\\', \"''\", '<'], ['sources', 'have', 'his', 'place', 'of', 'birth', 'wrongly', 'at', 'pukerua', 'bay', '.', '--', '>', '\\\\nand', 'was'], ['father', \"'s\", 'films', 'since', 'his', 'birth', ',', 'namely', \"''the\", 'frighteners', \"''\", '(', '1996', ')', ',']]\n",
      "boşluk\n",
      "[['\\\\n|', 'birth_date', '=', '{', '{', 'birth', 'date', 'and', 'age|mf=yes|1946|12|18', '}', '}', '<', 'ref', '>', '{']]\n",
      "boşluk\n",
      " mf=yes 1946 12 18\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "import os,sys\n",
    "from nltk.corpus import gutenberg\n",
    "import urllib2\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract(lst):\n",
    "    if extractUnproperDateFromData(lst):\n",
    "        return extractUnproperDateFromData(lst)\n",
    "    elif  extractProperDateFromData(lst): \n",
    "        return  extractProperDateFromData(lst)\n",
    "    return \"Enter a person name\"\n",
    "\n",
    "def extractUnproperDateFromData(lst):\n",
    "    \n",
    " for i in range(0,len(lst[0])):\n",
    "        if lst[0][i] == \"date\" and lst[0][i+1] == \"of\" and lst[0][i+2] == \"birth\":\n",
    "            return lst[0][i+4]+\" \"+ lst[0][i+5]+ \" \" +lst[0][i+6]\n",
    " return False\n",
    "        \n",
    "def extractProperDateFromData(lst):    \n",
    " for i in range(0,len(lst[0])):\n",
    "    if \"age|\" in lst[0][i]:\n",
    "        return lst[0][i].replace(\"|\",\" \")[lst[0][i].index(\"|\"):]\n",
    " return False\n",
    "\n",
    "    \n",
    "def prepareDataForProccessing(NAME):\n",
    "    \n",
    "    data = urllib2.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&prop=revisions&titles=\"+ NAME + \"&rvprop=content&redirects=true&format=json\").read().decode('utf8')\n",
    "    tokenized_data = nltk.word_tokenize(str(data).lower())\n",
    "    #print tokenized_data\n",
    "    converted_data = nltk.Text(tokenized_data)\n",
    "    mydata=  nltk.ConcordanceIndex(converted_data.tokens, key = lambda s: s.lower())\n",
    "    concordance_txt = ([converted_data.tokens[map(lambda x: x-5 if (x-10)>0 else 0,[offset])[0]:offset+10]\n",
    "                        for offset in mydata.offsets(\"birth\")])\n",
    "    #print converted_data.tokens[map(lambda x: x-5 if (x-10)>0 else 0,[offset])[0]:offset+10]\n",
    "    return concordance_txt\n",
    "\n",
    "dataPrepared= prepareDataForProccessing(\"Barış_Manço\")\n",
    "dataPrepared2= prepareDataForProccessing(\"David_Bowie\")\n",
    "dataPrepared3= prepareDataForProccessing(\"Wes_Anderson\")\n",
    "dataPrepared4= prepareDataForProccessing(\"peter_jackson\")\n",
    "dataPrepared5= prepareDataForProccessing(\"Steven_Spielberg\")\n",
    "dataPrepared6= prepareDataForProccessing(\"Kazim_Karabekir\")\n",
    "\n",
    "\n",
    "print dataPrepared\n",
    "print \"boşluk\"\n",
    "print dataPrepared2\n",
    "print \"boşluk\"\n",
    "print dataPrepared3\n",
    "print \"boşluk\"\n",
    "print dataPrepared4\n",
    "print \"boşluk\"\n",
    "print dataPrepared5\n",
    "print \"boşluk\"\n",
    "print extract(dataPrepared5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Where', 'WRB'), ('is', 'VBZ'), ('colorado', 'VBN'), ('?', '.')]\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('is', '')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def extractVerb(possed_data):\n",
    "    for element in possed_data:\n",
    "        if element[1] == 'VBD' or element[1] == 'VBZ':\n",
    "            return element[0]\n",
    "\n",
    "def extractNoun(possed_data):\n",
    "    result =\"\"\n",
    "    for element in possed_data:\n",
    "        if element[1] == 'NNP':\n",
    "          result +=   element[0] + \"_\" \n",
    "    return result[0:len(result)-1]\n",
    "            \n",
    "\n",
    "question = \"Who is Bill Gates?\"\n",
    "\n",
    "question2 = \"Where is colorado?\"\n",
    "\n",
    "print nltk.pos_tag(nltk.word_tokenize(question2))\n",
    "\n",
    "\n",
    "def processQuestion(questionSentence): \n",
    "    tokenized_data = nltk.word_tokenize(questionSentence)\n",
    "    possed_data = nltk.pos_tag(tokenized_data)\n",
    "    return (extractVerb(possed_data),extractNoun(possed_data))\n",
    "\n",
    "\n",
    "\n",
    "print nltk.help.upenn_tagset('WRB')\n",
    "\n",
    "\n",
    "processQuestion(question2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = 23 July 1882\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
